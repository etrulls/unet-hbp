# Misc
force_hash = 'hbp3ch1-lr5-nodo-nobn-lr4-wd5-relu-dil2-noel'

# Data
dataset = 'hbp3-ch1'
normalization = 'data'
mirror_data = false
dilate_train_gt = 2
test_thresholds = 0, 2

# Network
output_size = 388, 388
model = 'UNet'
num_unet_steps = 4
num_unet_convs = 2
num_unet_filters = 64
activation = 'ReLU'
pooling = 'MaxPool'
use_dropout = false
use_batchnorm = false
init_type = 'xavier_normal'

# Optimization
loss = 'classification'
optimizer = 'Adam'
learning_rate = .0001
weight_decay = .00001
save_models_every = 250
sampler = 'uniform'
augment_rotation = '2d'
augment_flipping = 'yx'
#augment_elastic = 'simard'
augment_elastic = 'none'
elastic_params = 200, 100, 10, 15

# Validation/testing
check_train_every = 1000
check_val_every = 1000
check_test_every = 1000
xval_metric = 'jacc'
